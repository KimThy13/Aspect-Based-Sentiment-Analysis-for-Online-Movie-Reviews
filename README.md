# Aspect-Based Sentiment Analysis for Online Movie Reviews

This repository implements a two-phase pipeline for Aspect-Based Sentiment Analysis (ABSA) on English movie reviews using T5 and BART models. The system identifies aspect-level opinions and sentiment polarities from user-generated review texts.

## Overview

The pipeline consists of two main phases:

1. **Component Sentence Extraction**
   Splits a full movie review into separate component sentences, where each sentence expresses an independent opinion.

2. **Aspect-Based Sentiment Analysis (ABSA)**
   For each component sentence, the model extracts:

   * `aspect`: the aspect category (e.g., `Movie`)
   * `aspect term`: the word or phrase referring to the aspect (e.g., `movie, film,..`)
   * `opinion term`: the opinionated word or phrase (e.g., `bad, good,..`)
   * `sentiment`: the sentiment polarity (`Positive`, `Negative`, `Neutral`)

## Project Structure

```
.
project/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                             # Raw CSV data uploaded by the user
â”‚   â”‚   â””â”€â”€ absa_reviews.csv
â”‚   â”œâ”€â”€ processed/                       
â”‚   â””â”€â”€ preprocessed/                    # Split + tokenized datasets ready for training
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ component_extraction/         # Trained model checkpoints for component extraction
â”‚   â””â”€â”€ absa/                         # Trained model checkpoints for ABSA extraction
â”‚
â”œâ”€â”€ phase1_component_extraction/
â”‚   â””â”€â”€ preprocess.py                    # Preprocessing for component data
â”œâ”€â”€ phase2_absa_extraction/
â”‚   â””â”€â”€ preprocess.py                    # Preprocessing for ABSA data
â”‚
â”œâ”€â”€ pipeline/
â”‚   â””â”€â”€ run_pipeline.py                  # Full pipeline: raw input â†’ final ABSA results
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ clean_data.py                   # Cleaning data
â”‚   â”œâ”€â”€ data_loader.py                   # Load preprocessed tokenized datasets
â”‚   â”œâ”€â”€ prepare_data.py                  # Load and format raw CSV to usable datasets
â”‚   â”œâ”€â”€ evaluator.py                     # Evaluation functions for ABSA predictions
â”‚   â”œâ”€â”€ trainer.py                       # Generic T5 trainer for both phases
â”‚   â”œâ”€â”€ logger.py                       # logging
â”‚   â””â”€â”€ predictor.py                     # Inference script
â”‚
â”œâ”€â”€outputs/
â”‚   â”œâ”€â”€ component_model/              # Saved fine-tuned component model
â”‚   â”œâ”€â”€ absa_model/                   # Saved fine-tuned ABSA model
â”‚   â”œâ”€â”€ component_result/             # Predictions and metrics of component extraction
â”‚   â””â”€â”€ absa_result/                  # Predictions and metrics of ABSA extraction
â”‚
â”œâ”€â”€ main.py                              # Central CLI for training/inference/pipeline
â”œâ”€â”€ requirements.txt                     # Required Python packages
â”œâ”€â”€ .gitignore                           # Ignore cache, models, logs, etc.
â””â”€â”€ README.md                            # Project documentation
```

## Quick Start

### 1. Clean Raw Reviews (Optional)
```bash
python clean_reviews.py --input data/raw/raw_reviews.csv --output data/raw/full_dataset.csv
```
### 2. Prepare Data
```bash
python src/utils/prepare_data.py --input data/raw/full_dataset.csv --output data/processed/
```
### 3. Train and Evaluate Models
Train and evaluate both stages:

- Stage 1: Component Extraction

- Stage 2: ABSA Prediction

```bash
python main.py \
  --prepare_data \
  --train_component \
  --eval_component \
  --train_absa \
  --eval_absa \
  --component_model_type t5 \
  --absa_model_type bart
```
ğŸ“Œ Option:

- `--component_model_type` and `--absa_model_type`: `t5` of `bart`
- The results and output model will be saved at `outputs/`

---
### 4. Run Full Pipeline on New Reviews

Run full pipeline from raw reviews â†’ component â†’ ABSA:
```bash
python main.py \
  --run_pipeline \
  --pipeline_input data/raw/full_reviews.csv \
  --pipeline_output pipeline/output.csv \
  --component_model_type bart \
  --absa_model_type t5
```

ğŸ“„ `pipeline/output.csv` will contain: | full\_review | component | aspect | aspect\_term | opinion\_term | sentiment |

---

### Training Configuration (Optional)

| Flag              | Default | Description                                             |
| ----------------- | ------- | ------------------------------------------------------- |
| `--epochs`        | 20      | Number of training epochs                               |
| `--batch_size`    | 8       | Batch size per device                                   |
| `--lr`            | 3e-4    | Learning rate                                           |
| `--warmup_steps`  | 500     | Warm-up steps for learning rate scheduler               |
| `--weight_decay`  | 0.01    | Weight decay coefficient for optimizer (regularization) |
| `--save_strategy` | epoch   | When to save checkpoints (`epoch`, `steps`, etc.)       |
| `--max_length`    | 64      | Maximum generation length for predictions               |
| `--num_beams`     | 4       | Number of beams used in beam search (generation)        |
| `--output_dir`    | outputs | Directory to save models and evaluation results         |

---

## âš™ï¸ Model Settings

* Architectures: T5-base, BART-base
* Evaluation: Precision, Recall, F1-score, BLEU, ROUGE

---

## ğŸ“ Output Format

### ğŸ”¹ Component Extraction (Phase 1)

Each input review is split into one or more **component sentences**.
Output format: a list of shorter sentences focusing on specific parts/aspects of the review.

**Example:**

```
Input: The acting was great but the plot was too slow.
Output: ["The acting was great ; the plot was too slow"]
```

### ğŸ”¹ ABSA Extraction (Phase 2)

Each component sentence is converted into a structured string that captures the sentiment context.

**Format:**

```
aspect: <category>, aspect term: <term>, opinion term: <term>, sentiment: <label>
```

**Example:**

```
aspect: Acting, aspect term: acting, opinion term: superb, sentiment: Positive
```

---

## Requirements

Install dependencies via:
```bash
pip install -r requirements.txt
```
### Key Libraries

* transformers
* datasets
* torch
* scikit-learn
* evaluate
* rouge\_score
* emoji
* langdetect
* nltk
* beautifulsoup4
* pandas, tqdm


## ğŸ“š Citation

This project was developed as part of the undergraduate thesis by:

**Nguyá»…n Háº£i Ngá»c Huyá»n**

**Táº¡ HoÃ ng Kim Thy**

University of Science, Vietnam National University - Ho Chi Minh City (VNU-HCM)

Major: Data Science â€” Class of 2025


